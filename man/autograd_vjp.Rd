% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autograd_functional.R
\name{autograd_vjp}
\alias{autograd_vjp}
\title{Function that computes the dot product between a vector \code{v} and the
Jacobian of the given function at the point given by the inputs.}
\usage{
autograd_vjp(func, inputs, v = NULL, create_graph = FALSE, strict = FALSE)
}
\arguments{
\item{func}{an R function that takes \code{torch_tensor} inputs and returns
a list of \code{torch_tensor}s or a \code{torch_tensor}.}

\item{inputs}{inputs to the function \code{func} (a \code{torch_tensor} or list of \code{torch_tensor}s).}

\item{v}{The vector (a \code{torch_tensor} or list of \code{torch_tensor}s) for which the vector Jacobian
product is computed. Must be the same size as the output of \code{func}. This argument is optional
when the output of \code{func} contains a single element and (if it is not provided) will be set as
a \code{torch_tensor} containing a single \code{1}.}

\item{create_graph}{If \code{TRUE}, both the output and result will be computed in a differentiable
way. Note that when \code{strict} is \code{FALSE}, the result can not require gradients or be
disconnected from the inputs.  Defaults to \code{FALSE}.}

\item{strict}{If \code{TRUE}, an error will be raised when we detect that there exists an input
such that all the outputs are independent of it. If \code{FALSE}, we return a \code{torch_tensor} of
zeros as the vjp for said inputs, which is the expected mathematical value. Defaults to \code{FALSE}.}
}
\value{
A list with:
\itemize{
\item func_output: output of \code{func(inputs)}
\item vjp: result of the dot product with the same shape as the inputs.
}
}
\description{
Function that computes the dot product between a vector \code{v} and the
Jacobian of the given function at the point given by the inputs.
}
\examples{
if (torch_is_installed()) {
adder <- function(x, y) {
  return(2 * x + 3 * y)
}
inputs <- list(torch_rand(2), torch_rand(2))
v <- torch.ones(2)
autograd_vjp(adder, inputs, v)
}
}
